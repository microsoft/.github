{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaziwahidaltaher-droid/.github/blob/main/notebooks/Getting_started_with_google_colab_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wdj9RMfoGPC2"
      },
      "cell_type": "markdown",
      "source": [
        "Colab is making it easier than ever to integrate powerful Generative AI capabilities into your projects. We are launching public preview for a simple and intuitive Python library (google.colab.ai) to access state-of-the-art language models directly within Pro and Pro+ subscriber Colab environments.  This means subscribers can spend less time on configuration and set up and more time bringing their ideas to life. With just a few lines of code, you can now perform a variety of tasks:\n",
        "- Generate text\n",
        "- Translate languages\n",
        "- Write creative content\n",
        "- Categorize text\n",
        "\n",
        "Happy Coding!\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/Getting_started_with_google_colab_ai.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Ucchuu5vV3Jp",
        "outputId": "ef9b86d4-4187-4f2b-c779-bd15733480ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# @title List available models\n",
        "from google.colab import ai\n",
        "\n",
        "ai.list_models()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['google/gemini-2.5-flash', 'google/gemini-2.5-flash-lite']"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "execution_count": 114
    },
    {
      "metadata": {
        "id": "LjfCGEpzDsD9"
      },
      "cell_type": "markdown",
      "source": [
        "Choosing a Model\n",
        "The model names give you a hint about their capabilities and intended use:\n",
        "\n",
        "Pro: These are the most capable models, ideal for complex reasoning, creative tasks, and detailed analysis.\n",
        "\n",
        "Flash: These models are optimized for high speed and efficiency, making them great for summarization, chat applications, and tasks requiring rapid responses.\n",
        "\n",
        "Gemma: These are lightweight, open-weight models suitable for a variety of text generation tasks and are great for experimentation."
      ]
    },
    {
      "metadata": {
        "id": "R7taibpc7x2l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "bd5aea0c-5846-417f-a849-bd554f5a565f"
      },
      "cell_type": "code",
      "source": [
        "# @title Simple batch generation example\n",
        "# Only text-to-text input/output is supported\n",
        "from google.colab import ai\n",
        "\n",
        "response = ai.generate_text(\"What is the capital of France?\")\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIStatusError",
          "evalue": "Error code: 402 - {'message': 'Colab Models is only available to Colab Pro and Pro+ subscribers.', 'type': 'invalid_request_error'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIStatusError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1782392906.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is the capital of France?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/ai.py\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(prompt, model_name, stream)\u001b[0m\n\u001b[1;32m     83\u001b[0m   )\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m   response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     86\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'role'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'user'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'content'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIStatusError\u001b[0m: Error code: 402 - {'message': 'Colab Models is only available to Colab Pro and Pro+ subscribers.', 'type': 'invalid_request_error'}"
          ]
        }
      ],
      "execution_count": 115
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1fd99c3"
      },
      "source": [
        "## Visualize results (optional)\n",
        "\n",
        "### Subtask:\n",
        "Visualize the predictions of the tuned model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d084318"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a scatter plot of the actual vs. predicted values from the tuned Ridge model, add labels, title, a diagonal line for perfect predictions, and a grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "775a47d5"
      },
      "source": [
        "# Create a scatter plot of actual vs. predicted values for the tuned Ridge model\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test_engineered, y_pred_tuned_ridge, alpha=0.5)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs. Predicted Values (Tuned Ridge Regression)')\n",
        "\n",
        "# Add a diagonal line for perfect predictions\n",
        "# Determine the range for the diagonal line based on both actual and predicted values\n",
        "plot_range_tuned = [min(y_test_engineered.min(), y_pred_tuned_ridge.min()), max(y_test_engineered.max(), y_pred_tuned_ridge.max())]\n",
        "plt.plot(plot_range_tuned, plot_range_tuned, color='red', linestyle='--')\n",
        "\n",
        "# Add a grid\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "458db442"
      },
      "source": [
        "## Compare with previous models\n",
        "\n",
        "### Subtask:\n",
        "Compare the performance of the tuned model to the previously trained models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28ab2164"
      },
      "source": [
        "**Reasoning**:\n",
        "Print the performance metrics for all models and compare them to summarize the impact of feature engineering and hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fead6e74",
        "outputId": "f0fc29d4-02f9-4279-cca3-d9412685208d"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "# Store performance metrics in a dictionary\n",
        "performance_metrics = {\n",
        "    \"Initial Linear Regression (Original Features)\": {\"MSE\": mse, \"R2\": r2},\n",
        "    \"Ridge Regression (Original Features, Default)\": {\"MSE\": mse_ridge, \"R2\": r2_ridge},\n",
        "    \"Linear Regression (Engineered Features)\": {\"MSE\": mse_engineered, \"R2\": r2_engineered},\n",
        "    \"Tuned Ridge Regression (Engineered Features, Tuned)\": {\"MSE\": mse_tuned_ridge, \"R2\": r2_tuned_ridge}\n",
        "}\n",
        "\n",
        "# Print the performance metrics in a formatted way\n",
        "print(\"--- Model Performance Comparison ---\")\n",
        "for model_name, metrics in performance_metrics.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\"  Mean Squared Error (MSE): {metrics['MSE']:.2f}\")\n",
        "    print(f\"  R-squared (R2) Score: {metrics['R2']:.4f}\")\n",
        "\n",
        "# Summarize the findings\n",
        "print(\"\\n--- Performance Comparison Summary ---\")\n",
        "\n",
        "# Determine the best model based on MSE and R2\n",
        "best_mse_model = min(performance_metrics, key=lambda k: performance_metrics[k]['MSE'])\n",
        "best_r2_model = max(performance_metrics, key=lambda k: performance_metrics[k]['R2'])\n",
        "\n",
        "if best_mse_model == best_r2_model:\n",
        "    print(f\"The {best_mse_model} performed the best based on both MSE (lower is better) and R2 (higher is better).\")\n",
        "else:\n",
        "    print(f\"The {best_mse_model} performed the best based on MSE (lower is better).\")\n",
        "    print(f\"The {best_r2_model} performed the best based on R2 (higher is better).\")\n",
        "\n",
        "print(\"\\nImpact of Feature Engineering and Hyperparameter Tuning:\")\n",
        "\n",
        "# Compare Engineered Linear Regression to Initial Linear Regression\n",
        "if performance_metrics[\"Linear Regression (Engineered Features)\"][\"MSE\"] < performance_metrics[\"Initial Linear Regression (Original Features)\"][\"MSE\"] \\\n",
        "   and performance_metrics[\"Linear Regression (Engineered Features)\"][\"R2\"] > performance_metrics[\"Initial Linear Regression (Original Features)\"][\"R2\"]:\n",
        "    print(\"- Feature engineering improved the performance of the Linear Regression model.\")\n",
        "else:\n",
        "    print(\"- Feature engineering did not significantly improve the performance of the Linear Regression model.\")\n",
        "\n",
        "# Compare Tuned Ridge (Engineered) to Linear Regression (Engineered)\n",
        "if performance_metrics[\"Tuned Ridge Regression (Engineered Features, Tuned)\"][\"MSE\"] < performance_metrics[\"Linear Regression (Engineered Features)\"][\"MSE\"] \\\n",
        "   and performance_metrics[\"Tuned Ridge Regression (Engineered Features, Tuned)\"][\"R2\"] > performance_metrics[\"Linear Regression (Engineered Features)\"][\"R2\"]:\n",
        "    print(\"- Hyperparameter tuning of the Ridge model with engineered features further improved performance compared to the Linear Regression model with engineered features.\")\n",
        "else:\n",
        "     print(\"- Hyperparameter tuning of the Ridge model with engineered features did not significantly improve performance compared to the Linear Regression model with engineered features.\")\n",
        "\n",
        "# Compare Tuned Ridge (Engineered) to Default Ridge (Original)\n",
        "if performance_metrics[\"Tuned Ridge Regression (Engineered Features, Tuned)\"][\"MSE\"] < performance_metrics[\"Ridge Regression (Original Features, Default)\"][\"MSE\"] \\\n",
        "   and performance_metrics[\"Tuned Ridge Regression (Engineered Features, Tuned)\"][\"R2\"] > performance_metrics[\"Ridge Regression (Original Features, Default)\"][\"R2\"]:\n",
        "     print(\"- Hyperparameter tuning of the Ridge model with engineered features improved performance compared to the Ridge model with default hyperparameters.\")\n",
        "else:\n",
        "     print(\"- Hyperparameter tuning of the Ridge model with engineered features did not significantly improve performance compared to the Ridge model with default hyperparameters.\")"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Model Performance Comparison ---\n",
            "\n",
            "Initial Linear Regression (Original Features):\n",
            "  Mean Squared Error (MSE): 4634658406.22\n",
            "  R-squared (R2) Score: 0.6636\n",
            "\n",
            "Ridge Regression (Original Features, Default):\n",
            "  Mean Squared Error (MSE): 4634651616.32\n",
            "  R-squared (R2) Score: 0.6636\n",
            "\n",
            "Linear Regression (Engineered Features):\n",
            "  Mean Squared Error (MSE): 4552463037.86\n",
            "  R-squared (R2) Score: 0.6696\n",
            "\n",
            "Tuned Ridge Regression (Engineered Features, Tuned):\n",
            "  Mean Squared Error (MSE): 4552359506.89\n",
            "  R-squared (R2) Score: 0.6696\n",
            "\n",
            "--- Performance Comparison Summary ---\n",
            "The Tuned Ridge Regression (Engineered Features, Tuned) performed the best based on both MSE (lower is better) and R2 (higher is better).\n",
            "\n",
            "Impact of Feature Engineering and Hyperparameter Tuning:\n",
            "- Feature engineering improved the performance of the Linear Regression model.\n",
            "- Hyperparameter tuning of the Ridge model with engineered features further improved performance compared to the Linear Regression model with engineered features.\n",
            "- Hyperparameter tuning of the Ridge model with engineered features improved performance compared to the Ridge model with default hyperparameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f640e6d4"
      },
      "source": [
        "## Train the final model\n",
        "\n",
        "### Subtask:\n",
        "Train the chosen model with the best hyperparameters on the entire training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3864b74e"
      },
      "source": [
        "**Reasoning**:\n",
        "Get the best estimator from the GridSearchCV object and train it on the entire engineered training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb1dce30"
      },
      "source": [
        "# Get the best estimator from the GridSearchCV object\n",
        "best_ridge_model = grid_search.best_estimator_\n",
        "\n",
        "# Train the best estimator on the entire engineered training data\n",
        "best_ridge_model.fit(X_train_engineered, y_train_engineered)\n",
        "\n",
        "print(\"Best Ridge Regression model trained on the entire engineered training set.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3867202"
      },
      "source": [
        "## Update features for modeling\n",
        "\n",
        "### Subtask:\n",
        "Select the updated set of features (including the new ones) for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56aa010d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Select the log-transformed features to visualize\n",
        "features_to_visualize_log = ['total_rooms_log', 'median_income_log']\n",
        "\n",
        "# Create histograms for each selected log-transformed feature\n",
        "df[features_to_visualize_log].hist(bins=50, figsize=(10, 5))\n",
        "plt.tight_layout() # Adjust layout to prevent overlap\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c9d624d"
      },
      "source": [
        "# Update the features list to include log-transformed features and exclude original skewed ones\n",
        "features_engineered_transformed = ['longitude', 'latitude', 'housing_median_age',\n",
        "                                   'total_bedrooms', 'population', 'households',\n",
        "                                   'rooms_per_household', 'bedrooms_per_room', 'population_per_household',\n",
        "                                   'total_rooms_log', 'median_income_log']\n",
        "\n",
        "# Create a new DataFrame X_engineered_transformed by selecting these columns from df\n",
        "X_engineered_transformed = df[features_engineered_transformed]\n",
        "\n",
        "# Keep the target variable y as it is (the 'median_house_value' column from df)\n",
        "# y was already defined in a previous step as df['median_house_value']\n",
        "\n",
        "# Print the head of X_engineered_transformed and y to verify\n",
        "print(\"Head of X_engineered_transformed:\")\n",
        "display(X_engineered_transformed.head())\n",
        "\n",
        "print(\"\\nHead of y:\")\n",
        "display(y.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33d4932e"
      },
      "source": [
        "## Apply Transformations to Skewed Features\n",
        "\n",
        "### Subtask:\n",
        "Apply log transformation to skewed numerical features identified during exploration."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FoTxyfYmhYPH"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50c1cff1"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply log transformation to 'total_rooms' and 'median_income' to reduce skewness and display the head of the DataFrame to show the transformed columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37e75b8c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Apply log transformation to 'total_rooms' and 'median_income'\n",
        "# Add a small constant (e.g., 1) before taking the log to handle potential zero values,\n",
        "# although based on describe() output, these columns don't have zeros.\n",
        "# Using np.log1p which calculates log(1+x) is a robust way to handle this.\n",
        "df['total_rooms_log'] = np.log1p(df['total_rooms'])\n",
        "df['median_income_log'] = np.log1p(df['median_income'])\n",
        "\n",
        "# Display the head of the DataFrame to verify the new transformed columns\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4b589c8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Select a few numerical features to visualize\n",
        "features_to_visualize = ['housing_median_age', 'total_rooms', 'median_income', 'median_house_value']\n",
        "\n",
        "# Create histograms for each selected feature\n",
        "df[features_to_visualize].hist(bins=50, figsize=(15, 10))\n",
        "plt.tight_layout() # Adjust layout to prevent overlap\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e38b388"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a scatter plot of median_income vs. median_house_value\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df['median_income'], df['median_house_value'], alpha=0.5)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Median Income')\n",
        "plt.ylabel('Median House Value')\n",
        "plt.title('Relationship between Median Income and Median House Value')\n",
        "\n",
        "# Add a grid for better readability\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51e78673"
      },
      "source": [
        "## Split the data (if necessary)\n",
        "\n",
        "### Subtask:\n",
        "Split the updated dataset (`X_engineered`, `y`) into training and testing sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ac8f448"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the features and target into training and testing sets using train_test_split as instructed and print their shapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc5d10a6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train_engineered, X_test_engineered, y_train_engineered, y_test_engineered = train_test_split(X_engineered, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting sets\n",
        "print(f\"Shape of X_train_engineered: {X_train_engineered.shape}\")\n",
        "print(f\"Shape of X_test_engineered: {X_test_engineered.shape}\")\n",
        "print(f\"Shape of y_train_engineered: {y_train_engineered.shape}\")\n",
        "print(f\"Shape of y_test_engineered: {y_test_engineered.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7a020a4"
      },
      "source": [
        "**Reasoning**:\n",
        "Select the updated set of features for training the model, including the engineered features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "456aa011"
      },
      "source": [
        "# Define the list of features, including the original and engineered ones\n",
        "features_engineered = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
        "                       'total_bedrooms', 'population', 'households', 'median_income',\n",
        "                       'rooms_per_household', 'bedrooms_per_room', 'population_per_household']\n",
        "\n",
        "# Create a new DataFrame X_engineered by selecting these columns from df\n",
        "X_engineered = df[features_engineered]\n",
        "\n",
        "# Keep the target variable y as it is (the 'median_house_value' column from df)\n",
        "# y was already defined in a previous step as df['median_house_value']\n",
        "\n",
        "# Print the head of X_engineered and y to verify\n",
        "print(\"Head of X_engineered:\")\n",
        "display(X_engineered.head())\n",
        "\n",
        "print(\"\\nHead of y:\")\n",
        "display(y.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b43fab9e"
      },
      "source": [
        "## Identify potential new features\n",
        "\n",
        "### Subtask:\n",
        "Determine which existing features can be combined or transformed to create meaningful new features (e.g., ratios, polynomial features, interaction terms)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adbc82dc"
      },
      "source": [
        "**Reasoning**:\n",
        "Describe the rationale for choosing features to create based on the analysis of existing features and potential relationships."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9a2f488"
      },
      "source": [
        "# Rationale for choosing new features:\n",
        "# Based on domain knowledge and common practices in housing price prediction,\n",
        "# ratios of existing features can provide more meaningful insights into the\n",
        "# characteristics of a housing block group than the raw counts alone.\n",
        "\n",
        "# 1. Rooms per household ('rooms_per_household'):\n",
        "#    This ratio (total_rooms / households) can indicate the average number of rooms\n",
        "#    available per household in a block group. It might be a strong predictor\n",
        "#    of housing value, as larger houses (more rooms per household) are often\n",
        "#    associated with higher values.\n",
        "\n",
        "# 2. Bedrooms per room ('bedrooms_per_room'):\n",
        "#    This ratio (total_bedrooms / total_rooms) can provide an idea of the\n",
        "#    proportion of rooms that are bedrooms. A higher ratio might indicate\n",
        "#    a different type of housing stock which could influence the median house value.\n",
        "\n",
        "# 3. Population per household ('population_per_household'):\n",
        "#    This ratio (population / households) represents the average household size.\n",
        "#    Larger household sizes in a block group might correlate with different housing\n",
        "#    demands and potentially impact housing values.\n",
        "\n",
        "# These ratios normalize the counts by the number of households or rooms,\n",
        "# making them potentially more robust indicators than the raw counts themselves."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c4d97dd"
      },
      "source": [
        "## Create new features\n",
        "\n",
        "### Subtask:\n",
        "Write code to generate the new features and add them to the DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9a73659"
      },
      "source": [
        "**Reasoning**:\n",
        "Generate the new features by calculating the ratios as described in the instructions and add them as new columns to the DataFrame. Then, display the head of the updated DataFrame to confirm the changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc30b3e9"
      },
      "source": [
        "# Calculate 'rooms_per_household' and add it as a new column\n",
        "df['rooms_per_household'] = df['total_rooms'] / df['households']\n",
        "\n",
        "# Calculate 'bedrooms_per_room' and add it as a new column\n",
        "df['bedrooms_per_room'] = df['total_bedrooms'] / df['total_rooms']\n",
        "\n",
        "# Calculate 'population_per_household' and add it as a new column\n",
        "df['population_per_household'] = df['population'] / df['households']\n",
        "\n",
        "# Display the head of the DataFrame to verify the new columns\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "088fbfe6"
      },
      "source": [
        "# Display summary statistics of the DataFrame\n",
        "display(df.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "990723df"
      },
      "source": [
        "## Visualize the results (optional)\n",
        "\n",
        "### Subtask:\n",
        "Visualize the predictions of the new model versus the actual values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f76956a7"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a scatter plot of the actual vs. predicted values from the Ridge model, add labels, title, a diagonal line for perfect predictions, and a grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "217c1753"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a scatter plot of actual vs. predicted values for the Ridge model\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred_ridge, alpha=0.5)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs. Predicted Values (Ridge Regression)')\n",
        "\n",
        "# Add a diagonal line for perfect predictions\n",
        "# Determine the range for the diagonal line based on both actual and predicted values\n",
        "plot_range = [min(y_test.min(), y_pred_ridge.min()), max(y_test.max(), y_pred_ridge.max())]\n",
        "plt.plot(plot_range, plot_range, color='red', linestyle='--')\n",
        "\n",
        "# Add a grid\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08f6f818"
      },
      "source": [
        "## Choose a new model\n",
        "\n",
        "### Subtask:\n",
        "Select a different regression algorithm to try (e.g., Ridge, Lasso, Decision Tree Regressor)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c407870"
      },
      "source": [
        "**Reasoning**:\n",
        "Choose a different regression algorithm and mention it in a markdown cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be170e13"
      },
      "source": [
        "# Choosing Ridge Regression as an alternative regression model.\n",
        "# Ridge is a linear model with L2 regularization.\n",
        "# It can help to prevent overfitting, especially when dealing with multicollinearity\n",
        "# among predictor variables, which might be present in this dataset.\n",
        "# This choice is a common next step after trying simple Linear Regression."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "805f79fa"
      },
      "source": [
        "## Train the new model\n",
        "\n",
        "### Subtask:\n",
        "Instantiate and train the chosen model using the training data (`X_train`, `y_train`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26859879"
      },
      "source": [
        "**Reasoning**:\n",
        "Instantiate and train the Ridge model using the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d79f43a6"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Instantiate a Ridge model object with default parameters\n",
        "ridge_model = Ridge()\n",
        "\n",
        "# Fit the Ridge model to the training data\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Ridge Regression model trained successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8addd87"
      },
      "source": [
        "## Visualize the results (optional)\n",
        "\n",
        "### Subtask:\n",
        "Visualize the predictions versus the actual values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "246fbfca"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a scatter plot of actual vs. predicted values and add a diagonal line for perfect predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5f468af"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs. Predicted Values')\n",
        "\n",
        "# Add a diagonal line for perfect predictions\n",
        "# Determine the range for the diagonal line\n",
        "plot_range = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]\n",
        "plt.plot(plot_range, plot_range, color='red', linestyle='--')\n",
        "\n",
        "# Add a grid\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e57b3e2a"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "* The `california_housing_train.csv` dataset was successfully loaded, containing 17000 entries and 9 columns of `float64` data type.\n",
        "* No missing values were found in the dataset after filling the initial missing values in `total_rooms` and `total_bedrooms` with their respective medians.\n",
        "* The dataset was split into training (13600 samples) and testing (3400 samples) sets, with features including 'longitude', 'latitude', 'housing\\_median\\_age', 'total\\_rooms', 'total\\_bedrooms', 'population', 'households', and 'median\\_income', and the target being 'median\\_house\\_value'.\n",
        "* A Linear Regression model was successfully trained on the training data.\n",
        "* The model achieved a Mean Squared Error (MSE) of approximately $4,634,658,406.22$ and an R-squared (R2) score of approximately 0.6636 on the testing data.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "* The R-squared score of 0.66 suggests the model explains a reasonable portion of the variance in median house values, but there is room for improvement.\n",
        "* Further steps could involve exploring feature engineering, trying different regression algorithms (e.g., Ridge, Lasso, or more complex models), or performing hyperparameter tuning to potentially improve the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1180b0f9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the original data points\n",
        "plt.scatter(X, y, color='blue', label='Original Data')\n",
        "\n",
        "# Plot the regression line\n",
        "# We need to predict y values for the range of X values to plot the line\n",
        "plt.plot(X, model.predict(X), color='red', label='Regression Line')\n",
        "\n",
        "plt.xlabel('Features (X)')\n",
        "plt.ylabel('Target (y)')\n",
        "plt.title('Linear Regression Example')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dddf50ae"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate some sample data\n",
        "# X represents the features (input), y represents the target (output)\n",
        "X = np.array([1, 2, 3, 4, 5, 6]).reshape(-1, 1) # Reshape for scikit-learn\n",
        "y = np.array([2, 4, 5, 4, 5, 6])\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model using the data\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make a prediction\n",
        "new_X = np.array([7]).reshape(-1, 1)\n",
        "prediction = model.predict(new_X)\n",
        "\n",
        "print(f\"Features (X):\\n{X}\")\n",
        "print(f\"Target (y):\\n{y}\")\n",
        "print(f\"Prediction for X={new_X[0][0]}: {prediction[0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NHO9VzO9AHZP"
      },
      "cell_type": "code",
      "source": [
        "# @title Choose a different model\n",
        "from google.colab import ai\n",
        "\n",
        "response = ai.generate_text(\"What is the capital of England\", model_name='google/gemini-2.0-flash-lite')\n",
        "print(response)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ysDdFbH_Dgtz"
      },
      "cell_type": "markdown",
      "source": [
        "For longer text generations, you can stream the response. This displays the output token by token as it's generated, rather than waiting for the entire response to complete. This provides a more interactive and responsive experience. To enable this, simply set stream=True."
      ]
    },
    {
      "metadata": {
        "id": "4BNgxiB6--_5"
      },
      "cell_type": "code",
      "source": [
        "# @title Simple streaming example\n",
        "from google.colab import ai\n",
        "\n",
        "stream = ai.generate_text(\"Tell me a short story.\", stream=True)\n",
        "for text in stream:\n",
        "  print(text, end='')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "CpMmpaVClSBV",
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Text formatting setup\n",
        "#code is not necessary for colab.ai, but is useful in fomatting text chunks\n",
        "import sys\n",
        "\n",
        "class LineWrapper:\n",
        "    def __init__(self, max_length=80):\n",
        "        self.max_length = max_length\n",
        "        self.current_line_length = 0\n",
        "\n",
        "    def print(self, text_chunk):\n",
        "        i = 0\n",
        "        n = len(text_chunk)\n",
        "        while i < n:\n",
        "            start_index = i\n",
        "            while i < n and text_chunk[i] not in ' \\n': # Find end of word\n",
        "                i += 1\n",
        "            current_word = text_chunk[start_index:i]\n",
        "\n",
        "            delimiter = \"\"\n",
        "            if i < n: # If not end of chunk, we found a delimiter\n",
        "                delimiter = text_chunk[i]\n",
        "                i += 1 # Consume delimiter\n",
        "\n",
        "            if current_word:\n",
        "                needs_leading_space = (self.current_line_length > 0)\n",
        "\n",
        "                # Case 1: Word itself is too long for a line (must be broken)\n",
        "                if len(current_word) > self.max_length:\n",
        "                    if needs_leading_space: # Newline if current line has content\n",
        "                        sys.stdout.write('\\n')\n",
        "                        self.current_line_length = 0\n",
        "                    for char_val in current_word: # Break the long word\n",
        "                        if self.current_line_length >= self.max_length:\n",
        "                            sys.stdout.write('\\n')\n",
        "                            self.current_line_length = 0\n",
        "                        sys.stdout.write(char_val)\n",
        "                        self.current_line_length += 1\n",
        "                # Case 2: Word doesn't fit on current line (print on new line)\n",
        "                elif self.current_line_length + (1 if needs_leading_space else 0) + len(current_word) > self.max_length:\n",
        "                    sys.stdout.write('\\n')\n",
        "                    sys.stdout.write(current_word)\n",
        "                    self.current_line_length = len(current_word)\n",
        "                # Case 3: Word fits on current line\n",
        "                else:\n",
        "                    if needs_leading_space:\n",
        "                        # Define punctuation that should not have a leading space\n",
        "                        # when they form an entire \"word\" (token) following another word.\n",
        "                        no_leading_space_punctuation = {\n",
        "                            \",\", \".\", \";\", \":\", \"!\", \"?\",        # Standard sentence punctuation\n",
        "                            \")\", \"]\", \"}\",                     # Closing brackets\n",
        "                            \"'s\", \"'S\", \"'re\", \"'RE\", \"'ve\", \"'VE\", # Common contractions\n",
        "                            \"'m\", \"'M\", \"'ll\", \"'LL\", \"'d\", \"'D\",\n",
        "                            \"n't\", \"N'T\",\n",
        "                            \"...\", \"â€¦\"                          # Ellipses\n",
        "                        }\n",
        "                        if current_word not in no_leading_space_punctuation:\n",
        "                            sys.stdout.write(' ')\n",
        "                            self.current_line_length += 1\n",
        "                    sys.stdout.write(current_word)\n",
        "                    self.current_line_length += len(current_word)\n",
        "\n",
        "            if delimiter == '\\n':\n",
        "                sys.stdout.write('\\n')\n",
        "                self.current_line_length = 0\n",
        "            elif delimiter == ' ':\n",
        "                # If line is full and a space delimiter arrives, it implies a wrap.\n",
        "                if self.current_line_length >= self.max_length:\n",
        "                    sys.stdout.write('\\n')\n",
        "                    self.current_line_length = 0\n",
        "\n",
        "        sys.stdout.flush()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "DWiLPzTnRoy-"
      },
      "cell_type": "code",
      "source": [
        "# @title Formatted streaming example\n",
        "from google.colab import ai\n",
        "\n",
        "wrapper = LineWrapper()\n",
        "for chunk in ai.generate_text('Give me a long winded description about the evolution of the Roman Empire.', model_name='google/gemini-2.0-flash', stream=True):\n",
        "  wrapper.print(chunk)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5851539"
      },
      "source": [
        "# Task\n",
        "Train a linear regression model on a more complex dataset from \"/content/sample_data/\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a7e5b4d"
      },
      "source": [
        "## Load the dataset\n",
        "\n",
        "### Subtask:\n",
        "Load a more complex dataset, such as one from the `/content/sample_data/` directory, into a pandas DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f24f0a9"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to load a dataset from `/content/sample_data/` into a pandas DataFrame. I need to import pandas and then use `pd.read_csv` to load a file. Displaying the head of the dataframe will confirm the data has been loaded.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8c9aec7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load a sample dataset from /content/sample_data/ - choosing california_housing_train.csv\n",
        "try:\n",
        "    df = pd.read_csv('/content/sample_data/california_housing_train.csv')\n",
        "    # Display the first few rows\n",
        "    display(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"File not found. Please check the file path.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff7bf690"
      },
      "source": [
        "## Explore and preprocess the data\n",
        "\n",
        "### Subtask:\n",
        "Inspect the dataset, handle any missing values, and select the features and target variable for the linear regression model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6383359c"
      },
      "source": [
        "**Reasoning**:\n",
        "Display DataFrame info, check for missing values, and handle them if necessary before selecting features and target variables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9347ab12"
      },
      "source": [
        "# Display info about the DataFrame\n",
        "df.info()\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Handle missing values if any.\n",
        "# The isnull().sum() output will show if there are any missing values.\n",
        "# Based on the output of isnull().sum(), if 'total_bedrooms' has missing values,\n",
        "# we will fill them with the median as it's a common practice for numerical features\n",
        "# and less sensitive to outliers than the mean.\n",
        "if df['total_bedrooms'].isnull().sum() > 0:\n",
        "    median_bedrooms = df['total_bedrooms'].median()\n",
        "    df['total_bedrooms'].fillna(median_bedrooms, inplace=True)\n",
        "    print(\"\\nMissing values in 'total_bedrooms' filled with median.\")\n",
        "\n",
        "# Also fill missing values in 'total_rooms' with the median\n",
        "if df['total_rooms'].isnull().sum() > 0:\n",
        "    median_rooms = df['total_rooms'].median()\n",
        "    df['total_rooms'].fillna(median_rooms, inplace=True)\n",
        "    print(\"Missing values in 'total_rooms' filled with median.\")\n",
        "\n",
        "print(df.isnull().sum()) # Verify after filling\n",
        "\n",
        "# Select features (X) and target variable (y)\n",
        "# We will use several numerical features as predictors for 'median_house_value'\n",
        "features = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
        "            'total_bedrooms', 'population', 'households', 'median_income']\n",
        "X = df[features]\n",
        "y = df['median_house_value']\n",
        "\n",
        "print(\"\\nFeatures (X) and Target (y) selected.\")\n",
        "display(X.head())\n",
        "display(y.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85d33c8f"
      },
      "source": [
        "## Split the data\n",
        "\n",
        "### Subtask:\n",
        "Split the dataset into training and testing sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1eda7b0"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the features and target into training and testing sets using train_test_split as instructed and print their shapes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94b0ab2d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting sets\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c3c850b"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "### Subtask:\n",
        "Train the linear regression model on the training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ecedb3e"
      },
      "source": [
        "**Reasoning**:\n",
        "Train the linear regression model using the training data (X_train and y_train).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3b32a6a"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Instantiate a Linear Regression model object\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Linear Regression model trained successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ed84711"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained model's performance on the testing data using appropriate metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76f31bb2"
      },
      "source": [
        "**Reasoning**:\n",
        "Evaluate the trained model's performance on the testing data using appropriate metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa02f998"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Use the trained model to make predictions on the testing features\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Calculate the R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the calculated metrics\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R-squared (R2) Score: {r2}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab47ee9a"
      },
      "source": [
        "## Visualize the results (optional)\n",
        "\n",
        "### Subtask:\n",
        "Visualize the predictions versus the actual values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f73af8ad"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a scatter plot of actual vs. predicted values and add a diagonal line for perfect predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fd07845"
      },
      "source": [
        "# Create a scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs. Predicted Values')\n",
        "\n",
        "# Add a diagonal line for perfect predictions\n",
        "# Determine the range for the diagonal line\n",
        "plot_range = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]\n",
        "plt.plot(plot_range, plot_range, color='red', linestyle='--')\n",
        "\n",
        "# Add a grid\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "745ce34d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The `california_housing_train.csv` dataset was successfully loaded, containing 17000 entries and 9 columns of `float64` data type.\n",
        "*   No missing values were found in the dataset, eliminating the need for imputation.\n",
        "*   The dataset was split into training (13600 samples) and testing (3400 samples) sets, with features including 'longitude', 'latitude', 'housing\\_median\\_age', 'total\\_rooms', 'total\\_bedrooms', 'population', 'households', and 'median\\_income', and the target being 'median\\_house\\_value'.\n",
        "*   A Linear Regression model was successfully trained on the training data.\n",
        "*   The model achieved a Mean Squared Error (MSE) of approximately $4,634,658,406.22$ and an R-squared (R2) score of approximately 0.6636 on the testing data.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The R-squared score of 0.66 suggests the model explains a reasonable portion of the variance in median house values, but there is room for improvement.\n",
        "*   Further steps could involve exploring feature engineering, trying different regression algorithms (e.g., Ridge, Lasso, or more complex models), or performing hyperparameter tuning to potentially improve the model's performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "624e20aa"
      },
      "source": [
        "# Task\n",
        "Generate a plan to train and evaluate a new regression model on the existing dataset, compare its performance to the previously trained linear regression model, and summarize the findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0b03c2e"
      },
      "source": [
        "## Choose a new model\n",
        "\n",
        "### Subtask:\n",
        "Select a different regression algorithm to try (e.g., Ridge, Lasso, Decision Tree Regressor).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a377d954"
      },
      "source": [
        "**Reasoning**:\n",
        "Choose a different regression algorithm and mention it in a markdown cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "866a3b17"
      },
      "source": [
        "# Choosing Ridge Regression as an alternative regression model.\n",
        "# Ridge is a linear model with L2 regularization.\n",
        "# It can help to prevent overfitting, especially when dealing with multicollinearity\n",
        "# among predictor variables, which might be present in this dataset.\n",
        "# This choice is a common next step after trying simple Linear Regression."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49297f4f"
      },
      "source": [
        "## Train the new model\n",
        "\n",
        "### Subtask:\n",
        "Instantiate and train the chosen model using the training data (`X_train`, `y_train`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ac64541"
      },
      "source": [
        "**Reasoning**:\n",
        "Instantiate and train the Ridge model using the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1722a73a"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Instantiate a Ridge model object with default parameters\n",
        "ridge_model = Ridge()\n",
        "\n",
        "# Fit the Ridge model to the training data\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Ridge Regression model trained successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2c9c397"
      },
      "source": [
        "## Evaluate the new model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the new model's performance on the testing data (`X_test`, `y_test`) using appropriate metrics (e.g., MSE, R2).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e06761a"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate MSE and R2 for the Ridge model using the test data and predictions, and print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24b91385"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Use the trained ridge_model to make predictions on the testing features\n",
        "y_pred_ridge = ridge_model.predict(X_test)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE) for the Ridge model\n",
        "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
        "\n",
        "# Calculate the R-squared score for the Ridge model\n",
        "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "\n",
        "# Print the calculated metrics for the Ridge model\n",
        "print(f\"Ridge Model Mean Squared Error (MSE): {mse_ridge}\")\n",
        "print(f\"Ridge Model R-squared (R2) Score: {r2_ridge}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eeeec40"
      },
      "source": [
        "## Compare model performance\n",
        "\n",
        "### Subtask:\n",
        "Compare the performance of the new model to the linear regression model we already trained.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc340fa9"
      },
      "source": [
        "**Reasoning**:\n",
        "Compare the performance metrics of the two models and print a summary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd0b8441"
      },
      "source": [
        "# Print the performance metrics for the Linear Regression model\n",
        "print(f\"Linear Regression Model Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Linear Regression Model R-squared (R2) Score: {r2}\")\n",
        "\n",
        "# Print the performance metrics for the Ridge Regression model\n",
        "print(f\"Ridge Model Mean Squared Error (MSE): {mse_ridge}\")\n",
        "print(f\"Ridge Model R-squared (R2) Score: {r2_ridge}\")\n",
        "\n",
        "# Compare and summarize the performance\n",
        "if mse_ridge < mse:\n",
        "    print(\"\\nSummary: The Ridge Regression model performed slightly better than the Linear Regression model based on MSE.\")\n",
        "elif mse_ridge > mse:\n",
        "    print(\"\\nSummary: The Linear Regression model performed slightly better than the Ridge Regression model based on MSE.\")\n",
        "else:\n",
        "    print(\"\\nSummary: Both models performed similarly based on MSE.\")\n",
        "\n",
        "if r2_ridge > r2:\n",
        "    print(\"Summary: The Ridge Regression model performed slightly better than the Linear Regression model based on R2.\")\n",
        "elif r2_ridge < r2:\n",
        "    print(\"Summary: The Linear Regression model performed slightly better than the Ridge Regression model based on R2.\")\n",
        "else:\n",
        "     print(\"Summary: Both models performed similarly based on R2.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16995797"
      },
      "source": [
        "## Visualize the results (optional)\n",
        "\n",
        "### Subtask:\n",
        "Visualize the predictions of the new model versus the actual values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5ab0a97"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a scatter plot of the actual vs. predicted values from the Ridge model, add labels, title, a diagonal line for perfect predictions, and a grid.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43d35683"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a scatter plot of actual vs. predicted values for the Ridge model\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred_ridge, alpha=0.5)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs. Predicted Values (Ridge Regression)')\n",
        "\n",
        "# Add a diagonal line for perfect predictions\n",
        "# Determine the range for the diagonal line based on both actual and predicted values\n",
        "plot_range = [min(y_test.min(), y_pred_ridge.min()), max(y_test.max(), y_pred_ridge.max())]\n",
        "plt.plot(plot_range, plot_range, color='red', linestyle='--')\n",
        "\n",
        "# Add a grid\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3db547b6"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Ridge Regression was chosen as an alternative model to Linear Regression.\n",
        "*   The Ridge Regression model was successfully trained on the training data.\n",
        "*   The Ridge Regression model achieved a Mean Squared Error (MSE) of approximately 4,634,651,616.32 on the test set.\n",
        "*   The Ridge Regression model achieved an R-squared (R2) score of approximately 0.6636 on the test set.\n",
        "*   Comparing to the Linear Regression model (MSE: 4,634,658,406.22, R2: 0.6636), the Ridge Regression model performed slightly better based on MSE and similarly based on R2.\n",
        "*   A scatter plot visualizing the actual versus predicted values for the Ridge model was generated, showing the distribution of predictions relative to a perfect prediction line.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Although Ridge Regression showed a minor improvement, the performance difference compared to Linear Regression is minimal, suggesting that the L2 regularization had a limited impact on this specific dataset.\n",
        "*   Further model exploration with different algorithms (e.g., tree-based models like Random Forest or Gradient Boosting) or hyperparameter tuning of the Ridge model could potentially yield better performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f4d030b"
      },
      "source": [
        "# Task\n",
        "Perform feature engineering on the `df` DataFrame to create new features, train a model with the updated features, and evaluate its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8eb897f"
      },
      "source": [
        "## Identify potential new features\n",
        "\n",
        "### Subtask:\n",
        "Determine which existing features can be combined or transformed to create meaningful new features (e.g., ratios, polynomial features, interaction terms).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3d68222"
      },
      "source": [
        "**Reasoning**:\n",
        "Describe the rationale for choosing features to create based on the analysis of existing features and potential relationships.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c95acba5"
      },
      "source": [
        "# Rationale for choosing new features:\n",
        "# Based on domain knowledge and common practices in housing price prediction,\n",
        "# ratios of existing features can provide more meaningful insights into the\n",
        "# characteristics of a housing block group than the raw counts alone.\n",
        "\n",
        "# 1. Rooms per household ('rooms_per_household'):\n",
        "#    This ratio (total_rooms / households) can indicate the average number of rooms\n",
        "#    available per household in a block group. It might be a strong predictor\n",
        "#    of housing value, as larger houses (more rooms per household) are often\n",
        "#    associated with higher values.\n",
        "\n",
        "# 2. Bedrooms per room ('bedrooms_per_room'):\n",
        "#    This ratio (total_bedrooms / total_rooms) can provide an idea of the\n",
        "#    proportion of rooms that are bedrooms. A higher ratio might indicate\n",
        "#    a different type of housing stock which could influence the median house value.\n",
        "\n",
        "# 3. Population per household ('population_per_household'):\n",
        "#    This ratio (population / households) represents the average household size.\n",
        "#    Larger household sizes in a block group might correlate with different housing\n",
        "#    demands and potentially impact housing values.\n",
        "\n",
        "# These ratios normalize the counts by the number of households or rooms,\n",
        "# making them potentially more robust indicators than the raw counts themselves."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "671d2b48"
      },
      "source": [
        "## Create new features\n",
        "\n",
        "### Subtask:\n",
        "Write code to generate the new features and add them to the DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a28da2f"
      },
      "source": [
        "**Reasoning**:\n",
        "Generate the new features by calculating the ratios as described in the instructions and add them as new columns to the DataFrame. Then, display the head of the updated DataFrame to confirm the changes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ca46b87"
      },
      "source": [
        "# Calculate 'rooms_per_household' and add it as a new column\n",
        "df['rooms_per_household'] = df['total_rooms'] / df['households']\n",
        "\n",
        "# Calculate 'bedrooms_per_room' and add it as a new column\n",
        "df['bedrooms_per_room'] = df['total_bedrooms'] / df['total_rooms']\n",
        "\n",
        "# Calculate 'population_per_household' and add it as a new column\n",
        "df['population_per_household'] = df['population'] / df['households']\n",
        "\n",
        "# Display the head of the DataFrame to verify the new columns\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7562b7a2"
      },
      "source": [
        "## Update features for modeling\n",
        "\n",
        "### Subtask:\n",
        "Select the updated set of features (including the new ones) for training the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98b24e8f"
      },
      "source": [
        "**Reasoning**:\n",
        "Select the updated set of features for training the model, including the engineered features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b6e7b39"
      },
      "source": [
        "# Define the list of features, including the original and engineered ones\n",
        "features_engineered = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
        "                       'total_bedrooms', 'population', 'households', 'median_income',\n",
        "                       'rooms_per_household', 'bedrooms_per_room', 'population_per_household']\n",
        "\n",
        "# Create a new DataFrame X_engineered by selecting these columns from df\n",
        "X_engineered = df[features_engineered]\n",
        "\n",
        "# Keep the target variable y as it is (the 'median_house_value' column from df)\n",
        "# y was already defined in a previous step as df['median_house_value']\n",
        "\n",
        "# Print the head of X_engineered and y to verify\n",
        "print(\"Head of X_engineered:\")\n",
        "display(X_engineered.head())\n",
        "\n",
        "print(\"\\nHead of y:\")\n",
        "display(y.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48e5c30c"
      },
      "source": [
        "## Split the data (if necessary)\n",
        "\n",
        "### Subtask:\n",
        "Split the updated dataset (`X_engineered`, `y`) into training and testing sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "069a70ad"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the features and target into training and testing sets using train_test_split as instructed and print their shapes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f346b39"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train_engineered, X_test_engineered, y_train_engineered, y_test_engineered = train_test_split(X_engineered, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting sets\n",
        "print(f\"Shape of X_train_engineered: {X_train_engineered.shape}\")\n",
        "print(f\"Shape of X_test_engineered: {X_test_engineered.shape}\")\n",
        "print(f\"Shape of y_train_engineered: {y_train_engineered.shape}\")\n",
        "print(f\"Shape of y_test_engineered: {y_test_engineered.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62522074"
      },
      "source": [
        "## Train a model with new features\n",
        "\n",
        "### Subtask:\n",
        "Train a regression model (either the Linear Regression or Ridge model again, or a new one) using the updated features (`X_train_engineered`, `y_train_engineered`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f00df49"
      },
      "source": [
        "**Reasoning**:\n",
        "Instantiate and train a Linear Regression model using the engineered training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f490841e"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Instantiate a Linear Regression model object\n",
        "model_engineered = LinearRegression()\n",
        "\n",
        "# Fit the model to the engineered training data\n",
        "model_engineered.fit(X_train_engineered, y_train_engineered)\n",
        "\n",
        "print(\"Linear Regression model trained successfully using engineered features.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f1cd2b0"
      },
      "source": [
        "## Evaluate the model with new features\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the model trained with the new features using appropriate metrics (e.g., MSE, R2) on the testing data (`X_test_engineered`, `y_test_engineered`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b82a5e8"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate MSE and R2 for the model trained with engineered features using the test data and predictions, and print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7df2324"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Use the trained model_engineered to make predictions on the engineered testing features\n",
        "y_pred_engineered = model_engineered.predict(X_test_engineered)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE) for the model with engineered features\n",
        "mse_engineered = mean_squared_error(y_test_engineered, y_pred_engineered)\n",
        "\n",
        "# Calculate the R-squared score for the model with engineered features\n",
        "r2_engineered = r2_score(y_test_engineered, y_pred_engineered)\n",
        "\n",
        "# Print the calculated metrics for the model with engineered features\n",
        "print(f\"Model with Engineered Features Mean Squared Error (MSE): {mse_engineered}\")\n",
        "print(f\"Model with Engineered Features R-squared (R2) Score: {r2_engineered}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ca80ee6"
      },
      "source": [
        "## Compare performance\n",
        "\n",
        "### Subtask:\n",
        "Compare the performance of the model with and without the new features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d308c1d0"
      },
      "source": [
        "**Reasoning**:\n",
        "Print the performance metrics for both models and compare them based on MSE and R2 to determine which model performed better.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0879e9ba"
      },
      "source": [
        "# Print the performance metrics for the Linear Regression model trained on original features\n",
        "print(f\"Linear Regression Model (Original Features) MSE: {mse}\")\n",
        "print(f\"Linear Regression Model (Original Features) R2 Score: {r2}\")\n",
        "\n",
        "# Print the performance metrics for the Linear Regression model trained on engineered features\n",
        "print(f\"Linear Regression Model (Engineered Features) MSE: {mse_engineered}\")\n",
        "print(f\"Linear Regression Model (Engineered Features) R2 Score: {r2_engineered}\")\n",
        "\n",
        "# Compare and summarize the performance based on MSE\n",
        "if mse_engineered < mse:\n",
        "    print(\"\\nSummary: The Linear Regression model with engineered features performed better than the model with original features based on MSE (lower is better).\")\n",
        "elif mse_engineered > mse:\n",
        "    print(\"\\nSummary: The Linear Regression model with original features performed better than the model with engineered features based on MSE (lower is better).\")\n",
        "else:\n",
        "    print(\"\\nSummary: Both Linear Regression models performed similarly based on MSE.\")\n",
        "\n",
        "# Compare and summarize the performance based on R2\n",
        "if r2_engineered > r2:\n",
        "    print(\"Summary: The Linear Regression model with engineered features performed better than the model with original features based on R2 (higher is better).\")\n",
        "elif r2_engineered < r2:\n",
        "    print(\"Summary: The Linear Regression model with original features performed better than the model with engineered features based on R2 (higher is better).\")\n",
        "else:\n",
        "    print(\"Summary: Both Linear Regression models performed similarly based on R2.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3c7a4ee"
      },
      "source": [
        "## Visualize results (optional)\n",
        "\n",
        "### Subtask:\n",
        "Visualize the predictions of the model trained with new features versus the actual values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63160aae"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a scatter plot of the actual vs. predicted values from the model trained with engineered features, add labels, title, a diagonal line for perfect predictions, and a grid.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29c83a42"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a scatter plot of actual vs. predicted values for the engineered features model\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test_engineered, y_pred_engineered, alpha=0.5)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs. Predicted Values (Linear Regression with Engineered Features)')\n",
        "\n",
        "# Add a diagonal line for perfect predictions\n",
        "# Determine the range for the diagonal line based on both actual and predicted values\n",
        "plot_range_engineered = [min(y_test_engineered.min(), y_pred_engineered.min()), max(y_test_engineered.max(), y_pred_engineered.max())]\n",
        "plt.plot(plot_range_engineered, plot_range_engineered, color='red', linestyle='--')\n",
        "\n",
        "# Add a grid\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f79ff4e"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Three new features were created: 'rooms\\_per\\_household', 'bedrooms\\_per\\_room', and 'population\\_per\\_household'.\n",
        "*   The dataset was successfully split into training (80%) and testing (20%) sets, resulting in training sets with 13600 samples and testing sets with 3400 samples.\n",
        "*   A Linear Regression model was trained using the dataset with the engineered features.\n",
        "*   The model trained with engineered features achieved a Mean Squared Error (MSE) of approximately 4,552,463,037.86 and an R-squared (R2) score of approximately 0.670 on the test set.\n",
        "*   Comparing the performance to the model with original features (MSE of ~4.63 billion and R2 of 0.664), the model with engineered features showed slightly better performance based on both metrics (lower MSE and higher R2).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The engineered features slightly improved the Linear Regression model's performance, suggesting that these ratios capture some valuable information about housing values. Further investigation into other feature engineering techniques or non-linear models could potentially yield more significant improvements.\n",
        "*   Visualizing the actual vs. predicted values confirms that the model's predictions generally follow the trend of the actual values, although there is still a notable spread, particularly for higher house values, indicating room for further model improvement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "077a42d1"
      },
      "source": [
        "# Task\n",
        "Explore Ridge or Lasso Regression for hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b52b9ea"
      },
      "source": [
        "## Choose a model for tuning\n",
        "\n",
        "### Subtask:\n",
        "Select either Ridge or Lasso Regression for hyperparameter tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "630393a2"
      },
      "source": [
        "## Define the parameter grid\n",
        "\n",
        "### Subtask:\n",
        "Specify the range of hyperparameter values to search over.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a0d3854"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a range of alpha values for hyperparameter tuning of the Ridge model and store them in a dictionary named `param_grid`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16943d5b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Choose a range of alpha values for Ridge Regression\n",
        "# Using a logarithmic scale from 0.1 to 100.\n",
        "alpha_range = np.logspace(-1, 2, 100)\n",
        "\n",
        "# Create a dictionary named param_grid\n",
        "param_grid = {'alpha': alpha_range}\n",
        "\n",
        "print(\"Hyperparameter grid for Ridge Regression:\")\n",
        "print(param_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a699be97"
      },
      "source": [
        "## Set up cross-validation\n",
        "\n",
        "### Subtask:\n",
        "Choose a cross-validation strategy (e.g., K-Fold) to evaluate different parameter combinations robustly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea3e61d1"
      },
      "source": [
        "**Reasoning**:\n",
        "Instantiate a KFold object with the specified parameters for cross-validation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b614f69b"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Instantiate a KFold object\n",
        "# n_splits=5 is a common choice for K-Fold cross-validation\n",
        "# shuffle=True shuffles the data before splitting, which is important if the data\n",
        "# has any inherent order.\n",
        "# random_state ensures that the shuffling is the same each time the code is run,\n",
        "# making the results reproducible.\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"KFold cross-validation strategy instantiated.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67bc814f"
      },
      "source": [
        "## Perform hyperparameter search\n",
        "\n",
        "### Subtask:\n",
        "Use a tuning method (e.g., GridSearchCV or RandomizedSearchCV) to find the best hyperparameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58664285"
      },
      "source": [
        "**Reasoning**:\n",
        "Instantiate and fit GridSearchCV to find the best hyperparameters for the Ridge model using the defined parameter grid and cross-validation strategy. Then, print the best parameters and best score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4be9680c"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Instantiate a GridSearchCV object\n",
        "# estimator: The model to tune (ridge_model)\n",
        "# param_grid: The grid of hyperparameters to search over\n",
        "# scoring: The metric to optimize (Negative Mean Squared Error, as GridSearchCV maximizes scores)\n",
        "# cv: The cross-validation strategy (kf)\n",
        "grid_search = GridSearchCV(estimator=ridge_model, param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error', cv=kf)\n",
        "\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train_engineered, y_train_engineered)\n",
        "\n",
        "# Print the best hyperparameters found by the search\n",
        "print(\"Best hyperparameters found by GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Print the best cross-validation score achieved during the search\n",
        "# Note: The score is negative MSE, so we take the negative to get the actual MSE\n",
        "print(\"\\nBest cross-validation MSE score:\")\n",
        "print(-grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c34eafb5"
      },
      "source": [
        "## Train the final model\n",
        "\n",
        "### Subtask:\n",
        "Train the chosen model with the best hyperparameters on the entire training set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bb1ff8e"
      },
      "source": [
        "**Reasoning**:\n",
        "Get the best estimator from the GridSearchCV object and train it on the entire engineered training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0c2ff41"
      },
      "source": [
        "# Get the best estimator from the GridSearchCV object\n",
        "best_ridge_model = grid_search.best_estimator_\n",
        "\n",
        "# Train the best estimator on the entire engineered training data\n",
        "best_ridge_model.fit(X_train_engineered, y_train_engineered)\n",
        "\n",
        "print(\"Best Ridge Regression model trained on the entire engineered training set.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfdf5774"
      },
      "source": [
        "## Evaluate the tuned model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the tuned model on the testing data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1de3530d"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate MSE and R2 for the tuned Ridge model using the test data and predictions, and print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c2707bc"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Use the trained best_ridge_model to make predictions on the engineered testing features\n",
        "y_pred_tuned_ridge = best_ridge_model.predict(X_test_engineered)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE) for the tuned Ridge model\n",
        "mse_tuned_ridge = mean_squared_error(y_test_engineered, y_pred_tuned_ridge)\n",
        "\n",
        "# Calculate the R-squared score for the tuned Ridge model\n",
        "r2_tuned_ridge = r2_score(y_test_engineered, y_pred_tuned_ridge)\n",
        "\n",
        "# Print the calculated metrics for the tuned Ridge model\n",
        "print(f\"Tuned Ridge Model Mean Squared Error (MSE): {mse_tuned_ridge}\")\n",
        "print(f\"Tuned Ridge Model R-squared (R2) Score: {r2_tuned_ridge}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c16553d"
      },
      "source": [
        "## Compare with previous models\n",
        "\n",
        "### Subtask:\n",
        "Compare the performance of the tuned model to the previously trained models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0724b9c"
      },
      "source": [
        "**Reasoning**:\n",
        "Print the performance metrics for all models and compare them to summarize the impact of feature engineering and hyperparameter tuning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "342f0d26"
      },
      "source": [
        "# Print the performance metrics for all models for comparison\n",
        "\n",
        "# Initial Linear Regression model (original features)\n",
        "print(f\"Initial Linear Regression Model (Original Features) MSE: {mse}\")\n",
        "print(f\"Initial Linear Regression Model (Original Features) R2 Score: {r2}\")\n",
        "\n",
        "# Ridge Regression model (original features, default hyperparameters)\n",
        "print(f\"Ridge Regression Model (Original Features, Default Hyperparameters) MSE: {mse_ridge}\")\n",
        "print(f\"Ridge Regression Model (Original Features, Default Hyperparameters) R2 Score: {r2_ridge}\")\n",
        "\n",
        "# Linear Regression model (engineered features)\n",
        "print(f\"Linear Regression Model (Engineered Features) MSE: {mse_engineered}\")\n",
        "print(f\"Linear Regression Model (Engineered Features) R2 Score: {r2_engineered}\")\n",
        "\n",
        "# Tuned Ridge Regression model (engineered features, tuned hyperparameters)\n",
        "print(f\"Tuned Ridge Regression Model (Engineered Features, Tuned Hyperparameters) MSE: {mse_tuned_ridge}\")\n",
        "print(f\"Tuned Ridge Regression Model (Engineered Features, Tuned Hyperparameters) R2 Score: {r2_tuned_ridge}\")\n",
        "\n",
        "# Summarize the findings\n",
        "print(\"\\n--- Performance Comparison Summary ---\")\n",
        "\n",
        "# Compare MSE\n",
        "if mse_tuned_ridge < mse_engineered and mse_tuned_ridge < mse_ridge and mse_tuned_ridge < mse:\n",
        "    print(\"The Tuned Ridge Regression model with engineered features performed the best based on MSE (lower is better).\")\n",
        "elif mse_engineered < mse_tuned_ridge and mse_engineered < mse_ridge and mse_engineered < mse:\n",
        "    print(\"The Linear Regression model with engineered features performed the best based on MSE (lower is better).\")\n",
        "elif mse_ridge < mse_tuned_ridge and mse_ridge < mse_engineered and mse_ridge < mse:\n",
        "    print(\"The Ridge Regression model with default hyperparameters performed the best based on MSE (lower is better).\")\n",
        "else:\n",
        "    print(\"The Initial Linear Regression model with original features performed the best based on MSE (lower is better).\")\n",
        "\n",
        "# Compare R2\n",
        "if r2_tuned_ridge > r2_engineered and r2_tuned_ridge > r2_ridge and r2_tuned_ridge > r2:\n",
        "    print(\"The Tuned Ridge Regression model with engineered features performed the best based on R2 (higher is better).\")\n",
        "elif r2_engineered > r2_tuned_ridge and r2_engineered > r2_ridge and r2_engineered > r2:\n",
        "    print(\"The Linear Regression model with engineered features performed the best based on R2 (higher is better).\")\n",
        "elif r2_ridge > r2_tuned_ridge and r2_ridge > r2_engineered and r2_ridge > r2:\n",
        "    print(\"The Ridge Regression model with default hyperparameters performed the best based on R2 (higher is better).\")\n",
        "else:\n",
        "    print(\"The Initial Linear Regression model with original features performed the best based on R2 (higher is better).\")\n",
        "\n",
        "print(\"\\nImpact of Feature Engineering and Hyperparameter Tuning:\")\n",
        "if mse_engineered < mse and r2_engineered > r2:\n",
        "    print(\"- Feature engineering improved the performance of the Linear Regression model.\")\n",
        "else:\n",
        "    print(\"- Feature engineering did not significantly improve the performance of the Linear Regression model.\")\n",
        "\n",
        "if mse_tuned_ridge < mse_engineered and r2_tuned_ridge > r2_engineered:\n",
        "    print(\"- Hyperparameter tuning of the Ridge model with engineered features further improved performance compared to the Linear Regression model with engineered features.\")\n",
        "else:\n",
        "    print(\"- Hyperparameter tuning of the Ridge model with engineered features did not significantly improve performance compared to the Linear Regression model with engineered features.\")\n",
        "\n",
        "if mse_tuned_ridge < mse_ridge and r2_tuned_ridge > r2_ridge:\n",
        "     print(\"- Hyperparameter tuning of the Ridge model with engineered features improved performance compared to the Ridge model with default hyperparameters.\")\n",
        "else:\n",
        "     print(\"- Hyperparameter tuning of the Ridge model with engineered features did not significantly improve performance compared to the Ridge model with default hyperparameters.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae3a5dad"
      },
      "source": [
        "## Visualize results (optional)\n",
        "\n",
        "### Subtask:\n",
        "Visualize the predictions of the tuned model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f7dba0d"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a scatter plot of the actual vs. predicted values from the tuned Ridge model, add labels, title, a diagonal line for perfect predictions, and a grid.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0845a2f0"
      },
      "source": [
        "# Create a scatter plot of actual vs. predicted values for the tuned Ridge model\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test_engineered, y_pred_tuned_ridge, alpha=0.5)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs. Predicted Values (Tuned Ridge Regression)')\n",
        "\n",
        "# Add a diagonal line for perfect predictions\n",
        "# Determine the range for the diagonal line based on both actual and predicted values\n",
        "plot_range_tuned = [min(y_test_engineered.min(), y_pred_tuned_ridge.min()), max(y_test_engineered.max(), y_pred_tuned_ridge.max())]\n",
        "plt.plot(plot_range_tuned, plot_range_tuned, color='red', linestyle='--')\n",
        "\n",
        "# Add a grid\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc0dada1"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The hyperparameter tuning process for the Ridge Regression model with engineered features identified an optimal `alpha` of 0.1.\n",
        "*   The best cross-validation Mean Squared Error (MSE) achieved during the grid search was approximately 5,070,263,224.18.\n",
        "*   The tuned Ridge Regression model with engineered features achieved a Mean Squared Error (MSE) of approximately 4,552,359,506.89 and an R-squared (R2) score of approximately 0.67 on the testing data.\n",
        "*   Feature engineering improved the performance of the Linear Regression model compared to using original features.\n",
        "*   Hyperparameter tuning of the Ridge model with engineered features further improved performance compared to both the Linear Regression model with engineered features and the Ridge model with default hyperparameters.\n",
        "*   The Tuned Ridge Regression model with engineered features was the best-performing model among those evaluated, based on the lowest MSE and highest R2 score.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The visualization of actual vs. predicted values for the tuned Ridge model shows a reasonable spread around the perfect prediction line, suggesting the model captures a significant portion of the variance but still has notable errors for some predictions.\n",
        "*   Further exploration could involve trying other regression algorithms (e.g., Lasso, ElasticNet, Gradient Boosting) or more advanced feature engineering techniques to potentially improve the model's performance further.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}